{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22cfc2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_ply_float_to_int(input_path, output_path, attr=\"object_id\"):\n",
    "    with open(input_path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    header = []\n",
    "    body = []\n",
    "    in_header = True\n",
    "    attr_line_index = -1\n",
    "\n",
    "    for i, line in enumerate(lines):\n",
    "        if in_header:\n",
    "            header.append(line)\n",
    "            if line.startswith(\"property float \" + attr):\n",
    "                attr_line_index = i\n",
    "                header[-1] = line.replace(\"property float \", \"property int \")\n",
    "            if line.strip() == \"end_header\":\n",
    "                in_header = False\n",
    "        else:\n",
    "            body.append(line)\n",
    "\n",
    "    # Rewrite body (convert the attribute column float->int)\n",
    "    new_body = []\n",
    "    for line in body:\n",
    "        parts = line.split()\n",
    "        if len(parts) > 3:  # vertex lines\n",
    "            # Object ID is last column\n",
    "            parts[-1] = str(int(float(parts[-1])))\n",
    "        new_body.append(\" \".join(parts) + \"\\n\")\n",
    "\n",
    "    with open(output_path, \"w\") as f:\n",
    "        f.writelines(header + new_body)\n",
    "\n",
    "    print(\"Wrote:\", output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3353e5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input = \"/home/student/ss/data/scene_datasets/trial/try/cube_attributes_semantic.ply\"\n",
    "# output = \"/home/student/ss/data/scene_datasets/trial/try/cube_attributes_semantic.ply\"\n",
    "\n",
    "# convert_ply_float_to_int(input, output, attr=\"object_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "414f95df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "\n",
    "def convert_ply_float_to_int_binary(input_path, output_path, attr=\"object_id\"):\n",
    "    with open(input_path, \"rb\") as f:\n",
    "        content = f.read()\n",
    "\n",
    "    # Find the end of the header\n",
    "    header_end = content.find(b\"end_header\\n\") + len(b\"end_header\\n\")\n",
    "    if header_end == -1:\n",
    "        raise RuntimeError(\"PLY header not found\")\n",
    "\n",
    "    # Decode header as ASCII\n",
    "    header = content[:header_end].decode(\"ascii\")\n",
    "\n",
    "    # Replace float property with int\n",
    "    new_header = header.replace(f\"property float {attr}\", f\"property int {attr}\")\n",
    "\n",
    "    # Parse number of vertices\n",
    "    vertex_count = 0\n",
    "    for line in header.split(\"\\n\"):\n",
    "        if line.startswith(\"element vertex\"):\n",
    "            vertex_count = int(line.split()[2])\n",
    "\n",
    "    # Extract property list for vertices\n",
    "    lines = header.split(\"\\n\")\n",
    "    vertex_props = []\n",
    "    reading = False\n",
    "    for line in lines:\n",
    "        if line.startswith(\"element vertex\"):\n",
    "            reading = True\n",
    "            continue\n",
    "        if reading:\n",
    "            if line.startswith(\"property\"):\n",
    "                vertex_props.append(line)\n",
    "            elif line.startswith(\"element\"):\n",
    "                break\n",
    "\n",
    "    prop_count = len(vertex_props)\n",
    "\n",
    "    # Which property index is object_id?\n",
    "    object_id_index = [\n",
    "        i for i, p in enumerate(vertex_props)\n",
    "        if p.endswith(f\" {attr}\")\n",
    "    ][0]\n",
    "\n",
    "    # Vertex block is prop_count * 4 bytes per vertex\n",
    "    vertex_data_size = vertex_count * prop_count * 4\n",
    "    vertex_data = content[header_end: header_end + vertex_data_size]\n",
    "\n",
    "    # Unpack all float32 values\n",
    "    floats = list(struct.unpack(\"<\" + \"f\" * (prop_count * vertex_count), vertex_data))\n",
    "\n",
    "    # Convert object_id from float → int\n",
    "    for v in range(vertex_count):\n",
    "        idx = v * prop_count + object_id_index\n",
    "        floats[idx] = int(floats[idx])\n",
    "\n",
    "    # Repack: for object_id use int32, others remain float32\n",
    "    new_vertex_data = bytearray()\n",
    "    for v in range(vertex_count):\n",
    "        for i in range(prop_count):\n",
    "            val = floats[v * prop_count + i]\n",
    "            if i == object_id_index:\n",
    "                new_vertex_data += struct.pack(\"<i\", int(val))\n",
    "            else:\n",
    "                new_vertex_data += struct.pack(\"<f\", float(val))\n",
    "\n",
    "    # Rest of file (faces)\n",
    "    remainder = content[header_end + vertex_data_size:]\n",
    "\n",
    "    # Write new PLY\n",
    "    with open(output_path, \"wb\") as f:\n",
    "        f.write(new_header.encode(\"ascii\"))\n",
    "        f.write(new_vertex_data)\n",
    "        f.write(remainder)\n",
    "\n",
    "    print(\"Converted binary PLY written to:\", output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c78a01f0",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "'i' format requires -2147483648 <= number <= 2147483647",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/student/ss/data/scene_datasets/sim/stages/cube_stage_semantic_objectid.ply\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/student/ss/data/scene_datasets/sim/stages/cube_stage_semantic_objectidint.ply\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 4\u001b[0m convert_ply_float_to_int_binary(\u001b[38;5;28minput\u001b[39m, output, attr\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject_id\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[3], line 64\u001b[0m, in \u001b[0;36mconvert_ply_float_to_int_binary\u001b[0;34m(input_path, output_path, attr)\u001b[0m\n\u001b[1;32m     62\u001b[0m val \u001b[38;5;241m=\u001b[39m floats[v \u001b[38;5;241m*\u001b[39m prop_count \u001b[38;5;241m+\u001b[39m i]\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m object_id_index:\n\u001b[0;32m---> 64\u001b[0m     new_vertex_data \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39mpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<i\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mint\u001b[39m(val))\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     66\u001b[0m     new_vertex_data \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39mpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<f\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mfloat\u001b[39m(val))\n",
      "\u001b[0;31merror\u001b[0m: 'i' format requires -2147483648 <= number <= 2147483647"
     ]
    }
   ],
   "source": [
    "input = \"/home/student/ss/data/scene_datasets/sim/stages/cube_stage_semantic_objectid.ply\"\n",
    "output = \"/home/student/ss/data/scene_datasets/sim/stages/cube_stage_semantic_objectidint.ply\"\n",
    "\n",
    "convert_ply_float_to_int_binary(input, output, attr=\"object_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff52af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed PLY written to: /home/student/ss/data/scene_datasets/sim/stages/cube_stage_semantic_objectidint.ply\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "from plyfile import PlyData, PlyElement\n",
    "import numpy as np\n",
    "import struct\n",
    "\n",
    "input_file = \"/home/student/ss/data/scene_datasets/sim/stages/cube_stage_semantic_objectid.ply\"\n",
    "output_file = \"/home/student/ss/data/scene_datasets/sim/stages/cube_stage_semantic_objectidint.ply\"\n",
    "\n",
    "# Load the binary PLY using plyfile\n",
    "plydata = PlyData.read(input_file)\n",
    "\n",
    "# Extract vertex data\n",
    "vertices = plydata['vertex'].data\n",
    "\n",
    "# Create new structured array with int object_id\n",
    "new_vertex_dtype = [('x','f4'), ('y','f4'), ('z','f4'),\n",
    "                    ('red','u1'), ('green','u1'), ('blue','u1'),\n",
    "                    ('alpha','u1'),\n",
    "                    ('object_id','i4')]\n",
    "\n",
    "new_vertices = np.empty(len(vertices), dtype=new_vertex_dtype)\n",
    "\n",
    "# Copy data and convert object_id to int\n",
    "new_vertices['x'] = vertices['x']\n",
    "new_vertices['y'] = vertices['y']\n",
    "new_vertices['z'] = vertices['z']\n",
    "new_vertices['red'] = vertices['red']\n",
    "new_vertices['green'] = vertices['green']\n",
    "new_vertices['blue'] = vertices['blue']\n",
    "new_vertices['alpha'] = vertices['alpha']\n",
    "# new_vertices['s'] = vertices['s']\n",
    "# new_vertices['t'] = vertices['t']\n",
    "new_vertices['object_id'] = vertices['object_id'].astype(np.int32)\n",
    "\n",
    "# Write fixed binary PLY\n",
    "ply_el = PlyElement.describe(new_vertices, 'vertex')\n",
    "PlyData([ply_el, plydata['face']], text=False).write(output_file)\n",
    "\n",
    "print(\"Fixed PLY written to:\", output_file)\n",
    "\n",
    "print(len(plydata['vertex'].data))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e574f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ SoundSpaces-ready PLY written to: /home/student/ss/data/scene_datasets/trial/try/cube_attributes_semantic_FIXED.ply\n",
      "Number of vertices: 14, Number of faces: 12\n"
     ]
    }
   ],
   "source": [
    "from plyfile import PlyData, PlyElement\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Input Blender-exported PLY\n",
    "input_file = \"/home/student/ss/data/scene_datasets/trial/try/cube_attributes_semantic.ply\"\n",
    "# Output SoundSpaces-ready PLY\n",
    "output_file = \"/home/student/ss/data/scene_datasets/trial/try/cube_attributes_semantic.ply\"\n",
    "\n",
    "# Check if input exists\n",
    "if not os.path.isfile(input_file):\n",
    "    raise FileNotFoundError(f\"Input file not found: {input_file}\")\n",
    "\n",
    "# Load binary PLY\n",
    "plydata = PlyData.read(input_file)\n",
    "\n",
    "# Extract vertex and face data\n",
    "vertices = plydata['vertex'].data\n",
    "faces = plydata['face'].data\n",
    "\n",
    "num_vertices = len(vertices)\n",
    "num_faces = len(faces)\n",
    "\n",
    "# Define new structured array dtype: x,y,z, RGB, object_id (object_id last)\n",
    "vertex_dtype = [\n",
    "    ('x', 'f4'), ('y', 'f4'), ('z', 'f4'),\n",
    "    ('red', 'u1'), ('green', 'u1'), ('blue', 'u1'),\n",
    "    ('object_id', 'i4')\n",
    "]\n",
    "\n",
    "new_vertices = np.empty(num_vertices, dtype=vertex_dtype)\n",
    "\n",
    "# Copy positions\n",
    "new_vertices['x'] = vertices['x']\n",
    "new_vertices['y'] = vertices['y']\n",
    "new_vertices['z'] = vertices['z']\n",
    "\n",
    "# Copy or create vertex colors\n",
    "if all(c in vertices.dtype.names for c in ['red', 'green', 'blue']):\n",
    "    new_vertices['red'] = vertices['red']\n",
    "    new_vertices['green'] = vertices['green']\n",
    "    new_vertices['blue'] = vertices['blue']\n",
    "else:\n",
    "    # Assign default white color if missing\n",
    "    new_vertices['red'] = 255\n",
    "    new_vertices['green'] = 255\n",
    "    new_vertices['blue'] = 255\n",
    "\n",
    "# Convert object_id to int32\n",
    "if 'object_id' in vertices.dtype.names:\n",
    "    new_vertices['object_id'] = vertices['object_id'].astype(np.int32)\n",
    "else:\n",
    "    # Default to 0 if missing\n",
    "    new_vertices['object_id'] = np.zeros(num_vertices, dtype=np.int32)\n",
    "\n",
    "# Create PLY elements\n",
    "vertex_element = PlyElement.describe(new_vertices, 'vertex')\n",
    "face_element = PlyElement.describe(faces, 'face')\n",
    "\n",
    "# Write binary little-endian PLY\n",
    "PlyData([vertex_element, face_element], text=False).write(output_file)\n",
    "\n",
    "print(f\"✅ SoundSpaces-ready PLY written to: {output_file}\")\n",
    "print(f\"Number of vertices: {num_vertices}, Number of faces: {num_faces}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9912cb7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vertex properties: ('x', 'y', 'z', 'red', 'green', 'blue', 'object_id')\n",
      "Number of vertices: 14\n",
      "Number of faces: 12\n",
      "[('x', '<f4'), ('y', '<f4'), ('z', '<f4'), ('red', 'u1'), ('green', 'u1'), ('blue', 'u1'), ('object_id', '<i4')]\n",
      "[('vertex_indices', 'O')]\n",
      "Max face index: 13\n"
     ]
    }
   ],
   "source": [
    "from plyfile import PlyData\n",
    "\n",
    "ply = PlyData.read(input_file)\n",
    "\n",
    "# Get vertex data as structured array\n",
    "vertex_data = ply['vertex'].data\n",
    "face_data = ply['face'].data\n",
    "\n",
    "# Print vertex property names\n",
    "print(\"Vertex properties:\", vertex_data.dtype.names)\n",
    "\n",
    "# Print number of vertices and faces\n",
    "print(\"Number of vertices:\", len(vertex_data))\n",
    "print(\"Number of faces:\", len(face_data))\n",
    "\n",
    "print(vertex_data.dtype)\n",
    "print(face_data.dtype)\n",
    "face_indices = face_data['vertex_indices']\n",
    "max_index = max(max(f) for f in face_indices)\n",
    "print(\"Max face index:\", max_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b531aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vertices: 14, Number of faces: 12\n",
      "\n",
      "Checking face indices...\n",
      "All face indices are valid ✅\n",
      "\n",
      "Checking object_ids against material JSON...\n",
      "All object_ids valid ✅\n",
      "\n",
      "✅ Fixed SoundSpaces-ready PLY written to: /home/student/ss/data/scene_datasets/trial/try/cube_attributes_semantic.ply\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from plyfile import PlyData, PlyElement\n",
    "\n",
    "# ===== INPUT/OUTPUT FILES =====\n",
    "ply_file = \"/home/student/ss/data/scene_datasets/trial/try/cube_attributes_semantic.ply\"\n",
    "material_json_file = \"/home/student/ss/data/mp3d_material_config.json\"\n",
    "output_file = \"/home/student/ss/data/scene_datasets/trial/try/cube_attributes_semantic.ply\"\n",
    "\n",
    "# ===== LOAD PLY =====\n",
    "plydata = PlyData.read(ply_file)\n",
    "vertex_data = plydata['vertex'].data\n",
    "face_data = plydata['face'].data\n",
    "num_vertices = len(vertex_data)\n",
    "num_faces = len(face_data)\n",
    "\n",
    "print(f\"Number of vertices: {num_vertices}, Number of faces: {num_faces}\")\n",
    "\n",
    "# ===== VALIDATE FACE INDICES =====\n",
    "print(\"\\nChecking face indices...\")\n",
    "faces_ok = True\n",
    "for i, f in enumerate(face_data['vertex_indices']):\n",
    "    for idx in f:\n",
    "        if idx >= num_vertices or idx < 0:\n",
    "            print(f\"Face {i} has out-of-range index: {f}\")\n",
    "            faces_ok = False\n",
    "\n",
    "if faces_ok:\n",
    "    print(\"All face indices are valid ✅\")\n",
    "\n",
    "# ===== VALIDATE AND FIX object_id VS MATERIAL JSON =====\n",
    "print(\"\\nChecking object_ids against material JSON...\")\n",
    "\n",
    "with open(material_json_file, 'r') as f:\n",
    "    material_config = json.load(f)\n",
    "\n",
    "material_list = material_config[\"materials\"]\n",
    "num_materials = len(material_list)  # valid object_id indices: 0 .. num_materials-1\n",
    "\n",
    "# Copy vertex data to a structured array we can modify\n",
    "vertex_dtype = vertex_data.dtype.descr\n",
    "new_vertices = np.empty(len(vertex_data), dtype=vertex_dtype)\n",
    "for name in vertex_data.dtype.names:\n",
    "    new_vertices[name] = vertex_data[name]\n",
    "\n",
    "# Check and fix object_id\n",
    "object_ids = np.unique(new_vertices['object_id'])\n",
    "missing_ids = []\n",
    "\n",
    "for i in range(len(new_vertices)):\n",
    "    oid = new_vertices['object_id'][i]\n",
    "    if oid >= num_materials or oid < 0:\n",
    "        missing_ids.append(oid)\n",
    "        # Map invalid ID to default material (0)\n",
    "        new_vertices['object_id'][i] = 0\n",
    "\n",
    "if missing_ids:\n",
    "    print(\"Warning ⚠: Fixed invalid object_ids:\", set(missing_ids))\n",
    "else:\n",
    "    print(\"All object_ids valid ✅\")\n",
    "\n",
    "# ===== WRITE FIXED PLY =====\n",
    "# Ensure object_id is the last property before end_header\n",
    "# PlyElement.describe preserves the order of the dtype\n",
    "vertex_element = PlyElement.describe(new_vertices, 'vertex')\n",
    "face_element = PlyElement.describe(face_data, 'face')\n",
    "PlyData([vertex_element, face_element], text=False).write(output_file)\n",
    "\n",
    "print(\"\\n✅ Fixed SoundSpaces-ready PLY written to:\", output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d725448e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max vertex index: 13\n",
      "Min vertex index: 0\n",
      "Degenerate faces: []\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from plyfile import PlyData\n",
    "\n",
    "plydata = PlyData.read(output_file)\n",
    "vertices = np.vstack([plydata['vertex']['x'],\n",
    "                      plydata['vertex']['y'],\n",
    "                      plydata['vertex']['z']]).T\n",
    "faces = plydata['face']['vertex_indices']\n",
    "\n",
    "# Flatten all face indices\n",
    "all_indices = np.hstack(faces)\n",
    "print(\"Max vertex index:\", all_indices.max())\n",
    "print(\"Min vertex index:\", all_indices.min())\n",
    "\n",
    "# Check for degenerate faces (rank < 3)\n",
    "degenerate = [i for i, f in enumerate(faces) \n",
    "              if np.linalg.matrix_rank(vertices[f]) < 3]\n",
    "print(\"Degenerate faces:\", degenerate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef14728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vertices: 8, Faces: 12\n",
      "No NaNs or Infs in vertex coordinates ✅\n",
      "No duplicate vertices ✅\n",
      "All face indices valid ✅\n",
      "No degenerate faces ✅\n",
      "All object_ids valid ✅\n",
      "\n",
      "PLY Validation Complete!\n",
      "Vertices: 8, Faces: 12\n",
      "Unique object_ids: [0 1]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from plyfile import PlyData\n",
    "\n",
    "# ===== INPUT FILES =====\n",
    "ply_file = \"/home/student/ss/data/scene_datasets/trial/try/cube_15153_semantic_from_blender.ply\"\n",
    "material_json_file = \"/home/student/ss/data/try_material_config.json\"\n",
    "\n",
    "# ===== LOAD PLY =====\n",
    "plydata = PlyData.read(ply_file)\n",
    "vertex_data = plydata['vertex'].data\n",
    "face_data = plydata['face'].data\n",
    "num_vertices = len(vertex_data)\n",
    "num_faces = len(face_data)\n",
    "\n",
    "print(f\"Vertices: {num_vertices}, Faces: {num_faces}\")\n",
    "\n",
    "# ===== CHECK FOR NaNs / INFs =====\n",
    "coords = np.vstack([vertex_data['x'], vertex_data['y'], vertex_data['z']]).T\n",
    "nan_mask = np.isnan(coords).any(axis=1)\n",
    "inf_mask = np.isinf(coords).any(axis=1)\n",
    "\n",
    "if nan_mask.any():\n",
    "    print(\"Warning ⚠: vertices with NaN coordinates at indices:\", np.where(nan_mask)[0])\n",
    "if inf_mask.any():\n",
    "    print(\"Warning ⚠: vertices with infinite coordinates at indices:\", np.where(inf_mask)[0])\n",
    "if not nan_mask.any() and not inf_mask.any():\n",
    "    print(\"No NaNs or Infs in vertex coordinates ✅\")\n",
    "\n",
    "# ===== CHECK FOR DUPLICATE VERTICES =====\n",
    "coords_tuple = [tuple(v) for v in coords]\n",
    "duplicates = [i for i, v in enumerate(coords_tuple) if coords_tuple.count(v) > 1]\n",
    "if duplicates:\n",
    "    print(\"Warning ⚠: Duplicate vertices found at indices:\", duplicates)\n",
    "else:\n",
    "    print(\"No duplicate vertices ✅\")\n",
    "\n",
    "# ===== CHECK FACE INDICES =====\n",
    "faces = face_data['vertex_indices']\n",
    "all_indices = np.hstack(faces)\n",
    "if all_indices.max() >= num_vertices or all_indices.min() < 0:\n",
    "    print(\"Warning ⚠: Face indices out of vertex range\")\n",
    "else:\n",
    "    print(\"All face indices valid ✅\")\n",
    "\n",
    "# ===== CHECK FOR DEGENERATE FACES =====\n",
    "degenerate_faces = [i for i, f in enumerate(faces)\n",
    "                    if np.linalg.matrix_rank(coords[f]) < 3]\n",
    "if degenerate_faces:\n",
    "    print(\"Warning ⚠: Degenerate faces (rank < 3) at indices:\", degenerate_faces)\n",
    "else:\n",
    "    print(\"No degenerate faces ✅\")\n",
    "\n",
    "# ===== VALIDATE object_id VS MATERIAL JSON =====\n",
    "with open(material_json_file, 'r') as f:\n",
    "    material_config = json.load(f)\n",
    "\n",
    "materials = material_config[\"materials\"]\n",
    "num_materials = len(materials)\n",
    "object_ids = np.unique(vertex_data['object_id'])\n",
    "\n",
    "invalid_ids = [oid for oid in object_ids if oid < 0 or oid >= num_materials]\n",
    "if invalid_ids:\n",
    "    print(f\"Warning ⚠: object_ids not in material JSON: {invalid_ids}\")\n",
    "else:\n",
    "    print(\"All object_ids valid ✅\")\n",
    "\n",
    "# ===== SUMMARY =====\n",
    "print(\"\\nPLY Validation Complete!\")\n",
    "print(f\"Vertices: {num_vertices}, Faces: {num_faces}\")\n",
    "print(f\"Unique object_ids: {object_ids}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c682ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed PLY written to: /home/student/ss/data/scene_datasets/trial/try/cube_15153_semantic.ply\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from plyfile import PlyData, PlyElement\n",
    "\n",
    "ply_file = \"/home/student/ss/data/scene_datasets/trial/try/cube_15153_semantic_from_blender.ply\"\n",
    "output_file = \"/home/student/ss/data/scene_datasets/trial/try/cube_15153_semantic.ply\"\n",
    "\n",
    "plydata = PlyData.read(ply_file)\n",
    "vertices = np.array([(v['x'], v['y'], v['z'], v['red'], v['green'], v['blue'], v['object_id'])\n",
    "                     for v in plydata['vertex'].data],\n",
    "                    dtype=[('x','f4'), ('y','f4'), ('z','f4'),\n",
    "                           ('red','u1'),('green','u1'),('blue','u1'),('object_id','i4')])\n",
    "\n",
    "faces = plydata['face']['vertex_indices']\n",
    "\n",
    "# Remove duplicate vertices\n",
    "coords = np.vstack([vertices['x'], vertices['y'], vertices['z']]).T\n",
    "_, unique_indices, inverse_map = np.unique(coords, axis=0, return_index=True, return_inverse=True)\n",
    "new_vertices = vertices[unique_indices]\n",
    "\n",
    "# Update face indices\n",
    "new_faces = np.array([inverse_map[f] for f in faces], dtype=object)\n",
    "\n",
    "# Create new PLY elements\n",
    "vertex_element = PlyElement.describe(new_vertices, 'vertex')\n",
    "face_element = PlyElement.describe(np.array([(f,) for f in new_faces], dtype=[('vertex_indices','O')]), 'face')\n",
    "\n",
    "# Write fixed PLY\n",
    "PlyData([vertex_element, face_element], text=False).write(output_file)\n",
    "print(\"Fixed PLY written to:\", output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1157ff21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 8\n"
     ]
    }
   ],
   "source": [
    "from plyfile import PlyData\n",
    "\n",
    "ply = PlyData.read(output_file)\n",
    "vertices = ply['vertex'].data\n",
    "print(len(vertices), len(vertices['object_id']))\n",
    "\n",
    "faces = ply['face'].data['vertex_indices']\n",
    "for f in faces:\n",
    "    for idx in f:\n",
    "        if idx >= len(vertices):\n",
    "            print(\"Invalid index!\", idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26823a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found mesh: Cube.001\n",
      "GLB verts: 8\n",
      "PLY verts: 8\n",
      "Max difference per axis: [0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "import trimesh\n",
    "import numpy as np\n",
    "\n",
    "# Load GLB\n",
    "glb = trimesh.load(\"/home/student/ss/data/scene_datasets/trial/try/cube_15153.glb\")\n",
    "\n",
    "# If GLB is a Scene, collect all vertices\n",
    "if isinstance(glb, trimesh.Scene):\n",
    "    glb_vertices = []\n",
    "    for name, geom in glb.geometry.items():\n",
    "        print(\"Found mesh:\", name)\n",
    "        glb_vertices.append(geom.vertices)\n",
    "    glb_vertices = np.vstack(glb_vertices)\n",
    "else:\n",
    "    glb_vertices = glb.vertices\n",
    "\n",
    "# Load PLY\n",
    "ply = trimesh.load(\"/home/student/ss/data/scene_datasets/trial/try/cube_15153_semantic.ply\")\n",
    "ply_vertices = ply.vertices\n",
    "\n",
    "print(\"GLB verts:\", len(glb_vertices))\n",
    "print(\"PLY verts:\", len(ply_vertices))\n",
    "\n",
    "# Check if vertex counts match\n",
    "if len(glb_vertices) != len(ply_vertices):\n",
    "    print(\"⚠️ Vertex count mismatch! AudioSensor will likely crash.\")\n",
    "else:\n",
    "    # Compare positions\n",
    "    diff = glb_vertices - ply_vertices\n",
    "    print(\"Max difference per axis:\", np.abs(diff).max(axis=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d48eadd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLY reordered to match GLB vertex order!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import trimesh\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "# Load GLB\n",
    "glb = trimesh.load(\"/home/student/ss/data/scene_datasets/trial/try/cube_15153.glb\")\n",
    "if isinstance(glb, trimesh.Scene):\n",
    "    glb_vertices = np.vstack([geom.vertices for geom in glb.geometry.values()])\n",
    "else:\n",
    "    glb_vertices = glb.vertices\n",
    "\n",
    "# Load PLY\n",
    "ply = trimesh.load(\"/home/student/ss/data/scene_datasets/trial/try/cube_15153_semantic.ply\")\n",
    "ply_vertices = ply.vertices\n",
    "\n",
    "# Build KD-tree from PLY vertices\n",
    "tree = cKDTree(ply_vertices)\n",
    "\n",
    "# For each GLB vertex, find nearest PLY vertex\n",
    "_, idx = tree.query(glb_vertices, k=1)\n",
    "\n",
    "# Reorder PLY vertices and colors/object_ids\n",
    "ply_vertices_reordered = ply_vertices[idx]\n",
    "ply_colors_reordered = ply.visual.vertex_colors[idx]\n",
    "\n",
    "# Update the PLY mesh\n",
    "ply.vertices = ply_vertices_reordered\n",
    "ply.visual.vertex_colors = ply_colors_reordered\n",
    "\n",
    "# Save fixed PLY\n",
    "ply.export(\"/home/student/ss/data/scene_datasets/trial/try/cube_15153_semantic_fixed.ply\")\n",
    "print(\"PLY reordered to match GLB vertex order!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fd0aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-7.5 -7.5  7.5]\n",
      " [-7.5  7.5  7.5]\n",
      " [-7.5 -7.5 -7.5]\n",
      " [-7.5  7.5 -7.5]\n",
      " [ 7.5 -7.5  7.5]\n",
      " [ 7.5  7.5  7.5]\n",
      " [ 7.5 -7.5 -7.5]\n",
      " [ 7.5  7.5 -7.5]]\n",
      "[[-7.5 -7.5  7.5]\n",
      " [-7.5  7.5  7.5]\n",
      " [-7.5 -7.5 -7.5]\n",
      " [-7.5  7.5 -7.5]\n",
      " [ 7.5 -7.5  7.5]\n",
      " [ 7.5  7.5  7.5]\n",
      " [ 7.5 -7.5 -7.5]\n",
      " [ 7.5  7.5 -7.5]]\n"
     ]
    }
   ],
   "source": [
    "print(ply.vertices)\n",
    "\n",
    "print(glb_vertices)\n",
    "\n",
    "assert ply.vertices.all() == glb_vertices.all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9baf8f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vertices: (8, 3)\n",
      "Faces: (12, 3)\n",
      "Any NaNs: False\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import trimesh\n",
    "\n",
    "ply = trimesh.load(\"/home/student/ss/data/scene_datasets/trial/try/cube_15153_semantic_fixed.ply\")\n",
    "print(\"Vertices:\", ply.vertices.shape)\n",
    "print(\"Faces:\", ply.faces.shape)\n",
    "print(\"Any NaNs:\", np.isnan(ply.vertices).any())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675dab1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<trimesh.Trimesh(vertices.shape=(8, 3), faces.shape=(12, 3))>\n"
     ]
    }
   ],
   "source": [
    "print(ply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df88ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLY reordered and object_id preserved! Saved to: /home/student/ss/data/scene_datasets/trial/try/cube_15153_semantic_fixed.ply\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import trimesh\n",
    "from scipy.spatial import cKDTree\n",
    "from plyfile import PlyData, PlyElement\n",
    "\n",
    "# Paths\n",
    "glb_path = \"/home/student/ss/data/scene_datasets/trial/try/cube_15153.glb\"\n",
    "ply_path = \"/home/student/ss/data/scene_datasets/trial/try/cube_15153_semantic.ply\"\n",
    "output_path = \"/home/student/ss/data/scene_datasets/trial/try/cube_15153_semantic_fixed.ply\"\n",
    "\n",
    "# Load GLB\n",
    "glb = trimesh.load(glb_path)\n",
    "if isinstance(glb, trimesh.Scene):\n",
    "    glb_vertices = np.vstack([geom.vertices for geom in glb.geometry.values()])\n",
    "else:\n",
    "    glb_vertices = glb.vertices\n",
    "\n",
    "# Load PLY with plyfile to access object_id\n",
    "plydata = PlyData.read(ply_path)\n",
    "vertex_data = plydata['vertex'].data\n",
    "ply_vertices = np.vstack([vertex_data['x'], vertex_data['y'], vertex_data['z']]).T\n",
    "ply_colors = np.vstack([vertex_data['red'], vertex_data['green'], vertex_data['blue']]).T\n",
    "obj_ids = vertex_data['object_id']\n",
    "\n",
    "# Build KD-tree from PLY vertices\n",
    "tree = cKDTree(ply_vertices)\n",
    "\n",
    "# For each GLB vertex, find nearest PLY vertex\n",
    "_, idx = tree.query(glb_vertices, k=1)\n",
    "\n",
    "# Reorder PLY vertices, colors, and object_ids\n",
    "ply_vertices_reordered = ply_vertices[idx]\n",
    "ply_colors_reordered = ply_colors[idx]\n",
    "obj_ids_reordered = obj_ids[idx]\n",
    "\n",
    "# Create structured array for export\n",
    "vertex_dtype = [\n",
    "    ('x', 'f4'), ('y', 'f4'), ('z', 'f4'),\n",
    "    ('red', 'u1'), ('green', 'u1'), ('blue', 'u1'),\n",
    "    ('object_id', 'i4')\n",
    "]\n",
    "vertex_data_out = np.empty(len(ply_vertices_reordered), dtype=vertex_dtype)\n",
    "vertex_data_out['x'] = ply_vertices_reordered[:, 0]\n",
    "vertex_data_out['y'] = ply_vertices_reordered[:, 1]\n",
    "vertex_data_out['z'] = ply_vertices_reordered[:, 2]\n",
    "vertex_data_out['red'] = ply_colors_reordered[:, 0]\n",
    "vertex_data_out['green'] = ply_colors_reordered[:, 1]\n",
    "vertex_data_out['blue'] = ply_colors_reordered[:, 2]\n",
    "vertex_data_out['object_id'] = obj_ids_reordered\n",
    "\n",
    "# Faces (unchanged)\n",
    "faces = np.array(plydata['face'].data, dtype=[('vertex_indices', 'i4', (3,))])\n",
    "\n",
    "# Export PLY\n",
    "ply_element = PlyElement.describe(vertex_data_out, 'vertex')\n",
    "face_element = PlyElement.describe(faces, 'face')\n",
    "PlyData([ply_element, face_element], text=False).write(output_path)\n",
    "\n",
    "print(f\"PLY reordered and object_id preserved! Saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc74a86a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vertices: 8, Faces: 12\n",
      "Object_id length:  8\n",
      "The object ids:  [0 1]\n",
      "Object_id dtype:  int32\n",
      "Unique object_ids: [0 1]\n",
      "✅ PLY semantic mesh validation passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import trimesh\n",
    "\n",
    "def validate_semantic_ply(ply_file, expected_vertices=None):\n",
    "    \"\"\"\n",
    "    Validates a Habitat semantic PLY mesh for audio simulation.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ply_file : str\n",
    "        Path to the PLY file.\n",
    "    expected_vertices : int or None\n",
    "        If provided, checks that the number of vertices matches.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bool\n",
    "        True if the PLY passes all checks, False otherwise.\n",
    "    \"\"\"\n",
    "\n",
    "    mesh = trimesh.load(ply_file)\n",
    "    \n",
    "    # --- Extract vertices and faces ---\n",
    "    if isinstance(mesh, trimesh.Scene):\n",
    "        # Combine all geometries\n",
    "        verts_list = []\n",
    "        faces_list = []\n",
    "        for name, geom in mesh.geometry.items():\n",
    "            verts_list.append(geom.vertices)\n",
    "            faces_list.append(geom.faces)\n",
    "        vertices = np.vstack(verts_list)\n",
    "        faces = np.vstack(faces_list)\n",
    "    else:\n",
    "        vertices = mesh.vertices\n",
    "        faces = mesh.faces\n",
    "    \n",
    "    print(f\"Vertices: {vertices.shape[0]}, Faces: {faces.shape[0]}\")\n",
    "    \n",
    "    # --- Vertex validation ---\n",
    "    if np.isnan(vertices).any():\n",
    "        print(\"ERROR: NaNs in vertex coordinates!\")\n",
    "        return False\n",
    "    if np.isinf(vertices).any():\n",
    "        print(\"ERROR: Infs in vertex coordinates!\")\n",
    "        return False\n",
    "    \n",
    "    if expected_vertices is not None and vertices.shape[0] != expected_vertices:\n",
    "        print(f\"WARNING: Vertex count {vertices.shape[0]} != expected {expected_vertices}\")\n",
    "\n",
    "    # --- Face validation ---\n",
    "    if faces.max() >= vertices.shape[0] or faces.min() < 0:\n",
    "        print(\"ERROR: Face indices out of range!\")\n",
    "        return False\n",
    "    degenerate_faces = [i for i, f in enumerate(faces) if len(set(f)) < 3]\n",
    "    if degenerate_faces:\n",
    "        print(f\"ERROR: Degenerate faces at indices {degenerate_faces}\")\n",
    "        return False\n",
    "    \n",
    "    # --- Object ID validation ---\n",
    "    obj_ids = None\n",
    "\n",
    "    # --- Attempt via trimesh ---\n",
    "    if hasattr(mesh, \"metadata\") and \"ply_raw\" in mesh.metadata:\n",
    "        # If object_id is in structured array\n",
    "        vertex_data = mesh.metadata[\"ply_raw\"][\"vertex\"]\n",
    "        obj_ids = vertex_data.get(\"object_id\", None)\n",
    "\n",
    "    if obj_ids is None:\n",
    "        # Try accessing vertex attributes via trimesh\n",
    "        try:\n",
    "            obj_ids = mesh.vertex_attributes[\"object_id\"]\n",
    "        except (AttributeError, KeyError):\n",
    "            obj_ids = None\n",
    "\n",
    "    # --- Fallback to plyfile if needed ---\n",
    "    if obj_ids is None and ply_path is not None:\n",
    "        try:\n",
    "            plydata = PlyData.read(ply_path)\n",
    "            obj_ids = np.array(plydata['vertex'].data['object_id'])\n",
    "        except Exception as e:\n",
    "            print(f\"WARNING: Failed to read object_id from PLY: {e}\")\n",
    "            obj_ids = None\n",
    "\n",
    "    # --- Validate object_ids ---\n",
    "    if obj_ids is not None:\n",
    "        obj_ids = np.array(obj_ids)\n",
    "        print(\"Object_id length: \", len(obj_ids))\n",
    "        print(\"The object ids: \", object_ids)\n",
    "        print(\"Object_id dtype: \", object_ids.dtype)\n",
    "        if not np.issubdtype(obj_ids.dtype, np.integer):\n",
    "            print(f\"ERROR: object_id array is not integer, dtype={obj_ids.dtype}\")\n",
    "            return False\n",
    "        if obj_ids.min() < 0:\n",
    "            print(\"ERROR: object_id has negative values!\")\n",
    "            return False\n",
    "        print(f\"Unique object_ids: {np.unique(obj_ids)}\")\n",
    "    else:\n",
    "        print(\"WARNING: object_id attribute not found. Habitat will fail.\")\n",
    "        return False\n",
    "\n",
    "    print(\"✅ PLY semantic mesh validation passed!\")\n",
    "    return True\n",
    "\n",
    "# --- Example usage ---\n",
    "ply_file = \"/home/student/ss/data/scene_datasets/trial/try/cube_15153_semantic.ply\"\n",
    "validate_semantic_ply(ply_file, expected_vertices=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a53de0",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/student/ss/data/scene_datasets/sim/stages/treated_room_object.ply'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# bl = PlyData.read(\"/home/student/ss/data/scene_datasets/sim/stages/treated_room_cube.ply\")\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# bl = PlyData.read(\"/home/student/ss/data/scene_datasets/sim/stages/treated_room.ply\")\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m bl \u001b[38;5;241m=\u001b[39m PlyData\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/student/ss/data/scene_datasets/sim/stages/treated_room_object.ply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# bl = PlyData.read(\"/home/student/ss/data/scene_datasets/sim/objects/treated_room_object_bbox.ply\")\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# bl = PlyData.read(\"/home/student/ss/data/scene_datasets/sim/stages/room_stage_semantic.ply\")\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# bl = PlyData.read(\"/home/student/ss/data/scene_datasets/mp3d/17DRP5sb8fy/17DRP5sb8fy_semantic_noObjectID.ply\")\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# bl = PlyData.read(\"/home/student/ss/data/scene_datasets/sim/stages/cube_stage_semantic.ply\")\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Get blender vertices\u001b[39;00m\n\u001b[1;32m     13\u001b[0m verts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(bl[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvertex\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdata)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/plyfile.py:157\u001b[0m, in \u001b[0;36mPlyData.read\u001b[0;34m(stream, mmap, known_list_len)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread\u001b[39m(stream, mmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc\u001b[39m\u001b[38;5;124m'\u001b[39m, known_list_len\u001b[38;5;241m=\u001b[39m{}):\n\u001b[1;32m    132\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;124;03m    Read PLY data from a readable file-like object or filename.\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;124;03m        indicates binary encoding.\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 157\u001b[0m     (must_close, stream) \u001b[38;5;241m=\u001b[39m _open_stream(stream, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    159\u001b[0m         data \u001b[38;5;241m=\u001b[39m PlyData\u001b[38;5;241m.\u001b[39m_parse_header(stream)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/plyfile.py:1352\u001b[0m, in \u001b[0;36m_open_stream\u001b[0;34m(stream, read_or_write)\u001b[0m\n\u001b[1;32m   1350\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, stream)\n\u001b[1;32m   1351\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1352\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28mopen\u001b[39m(stream, read_or_write[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m   1353\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   1354\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected open file or filename\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/student/ss/data/scene_datasets/sim/stages/treated_room_object.ply'"
     ]
    }
   ],
   "source": [
    "from plyfile import PlyData, PlyElement\n",
    "import numpy as np\n",
    "\n",
    "# bl = PlyData.read(\"/home/student/ss/data/scene_datasets/sim/stages/treated_room_cube.ply\")\n",
    "# bl = PlyData.read(\"/home/student/ss/data/scene_datasets/sim/stages/treated_room.ply\")\n",
    "bl = PlyData.read(\"/home/student/ss/data/scene_datasets/sim/stages/treated_room_object_semantic.ply\")\n",
    "# bl = PlyData.read(\"/home/student/ss/data/scene_datasets/sim/objects/treated_room_object_bbox.ply\")\n",
    "# bl = PlyData.read(\"/home/student/ss/data/scene_datasets/sim/stages/room_stage_semantic.ply\")\n",
    "# bl = PlyData.read(\"/home/student/ss/data/scene_datasets/mp3d/17DRP5sb8fy/17DRP5sb8fy_semantic_noObjectID.ply\")\n",
    "# bl = PlyData.read(\"/home/student/ss/data/scene_datasets/sim/stages/cube_stage_semantic.ply\")\n",
    "\n",
    "# Get blender vertices\n",
    "verts = np.array(bl['vertex'].data)\n",
    "\n",
    "# build new vertex dtype\n",
    "dtype = [\n",
    "    ('x', 'f4'), ('y', 'f4'), ('z', 'f4'),\n",
    "    ('red', 'u1'), ('green', 'u1'), ('blue', 'u1'),\n",
    "    ('object_id', 'i4')\n",
    "]\n",
    "\n",
    "new_verts = np.empty(len(verts), dtype=dtype)\n",
    "new_verts['x'] = verts['x']\n",
    "new_verts['y'] = verts['y']\n",
    "new_verts['z'] = verts['z']\n",
    "new_verts['red'] = verts['red']\n",
    "new_verts['green'] = verts['green']\n",
    "new_verts['blue'] = verts['blue']\n",
    "for v in range(len(new_verts)):\n",
    "    if new_verts['red'][v] == 254:\n",
    "        new_verts['object_id'][v] = 1\n",
    "    elif new_verts['green'][v] == 254:\n",
    "        new_verts['object_id'][v] = 0\n",
    "    elif new_verts['blue'][v] == 254:\n",
    "        new_verts['object_id'][v] = 2\n",
    "    else:\n",
    "        new_verts['object_id'][v] = 3\n",
    "\n",
    "# faces unchanged\n",
    "faces = bl['face']\n",
    "\n",
    "# # ASCII\n",
    "ply = PlyData(\n",
    "    [PlyElement.describe(new_verts, 'vertex'),\n",
    "     faces],\n",
    "    text=True)\n",
    "\n",
    "ply.write(\"/home/student/ss/data/scene_datasets/sim/stages/treated_room_object_semantic_ASCII.ply\")\n",
    "# ply.write(\"/home/student/ss/data/scene_datasets/sim/stages/treated_room_cube_semantic_ASCII.ply\")\n",
    "# ply.write(\"/home/student/ss/data/scene_datasets/sim/objects/treated_room_object_bbox_semantic_ASCII.ply\")\n",
    "# ply.write(\"/home/student/ss/data/scene_datasets/sim/stages/cube_stage_semantic_ASCII.ply\")\n",
    "\n",
    "# BINARY\n",
    "ply = PlyData(\n",
    "    [\n",
    "        PlyElement.describe(new_verts, 'vertex'),\n",
    "        faces,\n",
    "    ],\n",
    "    byte_order='<')\n",
    "# # ply.write(\"/home/student/ss/data/scene_datasets/sim/stages/treated_room_with_speaker_and_mic_semantic.ply\")\n",
    "# ply.write(\"/home/student/ss/data/scene_datasets/sim/stages/treated_room_cube_semantic.ply\")\n",
    "ply.write(\"/home/student/ss/data/scene_datasets/sim/stages/treated_room_object_semantic.ply\")\n",
    "# ply.write(\"/home/student/ss/data/scene_datasets/sim/objects/treated_room_object_bbox_semantic.ply\")\n",
    "# # ply.write(\"/home/student/ss/data/scene_datasets/sim/stages/treated_room_semantic.ply\")\n",
    "# ply.write(\"/home/student/ss/data/scene_datasets/sim/stages/cube_stage_semantic.ply\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "98fbfe75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n",
      "[('x', '<f4'), ('y', '<f4'), ('z', '<f4'), ('red', 'u1'), ('green', 'u1'), ('blue', 'u1'), ('object_id', '<i4')]\n",
      "[(2.5, -3.5, 0., 0, 0, 0, 3) (2.5, -3.5, 2., 0, 0, 0, 3)\n",
      " (2.5, -2.5, 0., 0, 0, 0, 3) (2.5, -2.5, 2., 0, 0, 0, 3)\n",
      " (3.5, -3.5, 0., 0, 0, 0, 3) (3.5, -3.5, 2., 0, 0, 0, 3)\n",
      " (3.5, -2.5, 0., 0, 0, 0, 3) (3.5, -2.5, 2., 0, 0, 0, 3)]\n",
      "[(3.5, -4.5, 0., 0, 0, 0, 3) (3.5, -4.5, 2., 0, 0, 0, 3)\n",
      " (3.5, -3.5, 0., 0, 0, 0, 3) (3.5, -3.5, 2., 0, 0, 0, 3)\n",
      " (4.5, -4.5, 0., 0, 0, 0, 3) (4.5, -4.5, 2., 0, 0, 0, 3)\n",
      " (4.5, -3.5, 0., 0, 0, 0, 3) (4.5, -3.5, 2., 0, 0, 0, 3)]\n"
     ]
    }
   ],
   "source": [
    "print(len(new_verts))\n",
    "print(new_verts.dtype)\n",
    "print(new_verts[-8:])\n",
    "new_verts[-8:]['x'] += 1.0\n",
    "new_verts[-8:]['y'] -= 1.0\n",
    "print(new_verts[-8:])\n",
    "\n",
    "ply = PlyData(\n",
    "    [\n",
    "        PlyElement.describe(new_verts, 'vertex'),\n",
    "        faces,\n",
    "    ],\n",
    "    byte_order='<')\n",
    "\n",
    "ply.write(\"/home/student/ss/data/scene_datasets/sim/stages/treated_room_object_moved_semantic.ply\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
