{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "270c7e11",
   "metadata": {},
   "source": [
    "# Dataset Creation - TRsim Experiment 3\n",
    "\n",
    "R = amount of starting configurations with B boxes\n",
    "\n",
    "B = amount of boxes in the room at the start\n",
    "\n",
    "## Step 1: Create the foundation files\n",
    "\n",
    "Within the folder data/scene_datasets/TRsim_exp3/stages/:\n",
    "\n",
    "- (1x) TRsim_room.glb: floor + walls + ceiling mesh.\n",
    "\n",
    "- (Rx) TRsim.ply: export the room, as well as the boxes.\n",
    "\n",
    "- (1x) TRsim.house: .house file describing the room geometry, and the box locations.\n",
    "\n",
    "Within the folder data/scene_datasets/TRsim_exp3/objects/:\n",
    "\n",
    "- (1x) TRsim_box.glb: box mesh.\n",
    "\n",
    "And:\n",
    "\n",
    "- (1x) TRsim_material_config.json: Acoustic properties file\n",
    "\n",
    "## Step 1: Modify the _semantic.ply\n",
    "\n",
    "Modify the .ply file to change the last x vertices (boxes) to different locations, as well as adding the right material \"object_id\". Save in the format \"~/ss/data/scene_datasets/TRsim_exp3/stages/TRsim_room{n}\\_{amount of boxes removed}\\_{ids of boxes removed}_semantic.ply\". \n",
    "\n",
    "## Step 2: Create ground truth label file\n",
    "\n",
    "The label is saved in the filename, as it corresponds to the amount of boxes removed.\n",
    "\n",
    "## Step 3: Run SoundSpaces 2.0\n",
    "\n",
    "Load the file, rename to \"treated_room_object_semantic.ply\", run simulation, and save as \"N.wav\".\n",
    "\n",
    "## Step 4: Concatenate mic channels\n",
    "\n",
    "For now, the simulations are saved per mic. For the multi-channel cases, these files need to be concatenated into one \"deconvolved.npy\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34cc7c1",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2af1de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from plyfile import PlyData, PlyElement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbb38dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/student/ss/data/scene_datasets/TRsim_exp3/stages\n"
     ]
    }
   ],
   "source": [
    "BASE_DIR = \"/home/student/ss\"\n",
    "SIM_DIR = os.path.join(BASE_DIR, \"data/scene_datasets/TRsim_exp3\")\n",
    "STAGES_DIR = os.path.join(BASE_DIR, SIM_DIR, \"stages\")\n",
    "print(STAGES_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12617d74",
   "metadata": {},
   "source": [
    "### Step 1: Modify the _semantic.ply\n",
    "\n",
    "Save with the name \"~/ss/data/scene_datasets/TRsim_exp3/stages/TRsim_room{n}\\_{amount of boxes removed}\\_{ids of boxes removed}_semantic.ply\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3b3f2f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def create_empty_ply(base_ply):\n",
    "    base_verts = np.array(base_ply['vertex'].data) # (40,), where the first 33 correspond to the room, the last 8 to the box\n",
    "\n",
    "    verts_dtype = [\n",
    "        ('x', 'f4'), ('y', 'f4'), ('z', 'f4'),\n",
    "        ('red', 'u1'), ('green', 'u1'), ('blue', 'u1'),\n",
    "        ('object_id', 'i4')] # remove the alpha, add the object_id\n",
    "    \n",
    "    new_verts = np.empty(len(base_verts), dtype=verts_dtype)\n",
    "\n",
    "    new_verts['x'] = base_verts['x'] # last 8 will be overwritten\n",
    "    new_verts['y'] = base_verts['y'] # last 8 will be overwritten\n",
    "    new_verts['z'] = base_verts['z'] # does not change between measurement locations (vertex order does not change)\n",
    "    new_verts['red'] = base_verts['red'] # same\n",
    "    new_verts['green'] = base_verts['green'] # same\n",
    "    new_verts['blue'] = base_verts['blue'] # same\n",
    "\n",
    "    for v in range(len(new_verts)): # set all materials, does not change between measurement locations (vertex order does not change)\n",
    "        if new_verts['red'][v] == 254:\n",
    "            new_verts['object_id'][v] = 1 # wall material\n",
    "        elif new_verts['green'][v] == 254:\n",
    "            new_verts['object_id'][v] = 0 # floor material\n",
    "        elif new_verts['blue'][v] == 254:\n",
    "            new_verts['object_id'][v] = 2 # ceiling material\n",
    "        else:\n",
    "            new_verts['object_id'][v] = 3 # object material        \n",
    "        \n",
    "    faces = base_ply['face'] # unchanged, just sets which vertice ids correspond to which face (and vertex order does not change)\n",
    "    \n",
    "    return new_verts, faces\n",
    "\n",
    "def remove_boxes_from_ply(new_verts, faces, boxes_to_remove):\n",
    "    \"\"\"\n",
    "    Remove multiple boxes at once.\n",
    "    boxes_to_remove: list of integers, the box indices to remove\n",
    "    \"\"\"\n",
    "    # Step 1: find all box vertices\n",
    "    is_box_vertex = new_verts['object_id'] == 3\n",
    "    box_vertex_indices_all = np.where(is_box_vertex)[0]\n",
    "\n",
    "    # Step 2: select the vertices corresponding to the boxes to remove\n",
    "    box_vertex_indices_to_remove = []\n",
    "    for box in boxes_to_remove:\n",
    "        start = box * 8\n",
    "        end = start + 8\n",
    "        box_vertex_indices_to_remove.extend(box_vertex_indices_all[start:end])\n",
    "    box_vertex_indices_to_remove = np.array(box_vertex_indices_to_remove)\n",
    "\n",
    "    # Step 3: remove faces referencing these vertices\n",
    "    faces_data = np.array(faces.data)\n",
    "    keep_face_mask = []\n",
    "    for face in faces_data:\n",
    "        vertex_ids = face['vertex_indices']\n",
    "        if not any(v in box_vertex_indices_to_remove for v in vertex_ids):\n",
    "            keep_face_mask.append(True)\n",
    "        else:\n",
    "            keep_face_mask.append(False)\n",
    "    keep_face_mask = np.array(keep_face_mask)\n",
    "    remaining_faces_data = faces_data[keep_face_mask]\n",
    "\n",
    "    # Step 4: remove the vertices\n",
    "    keep_vertex_mask = np.ones(len(new_verts), dtype=bool)\n",
    "    keep_vertex_mask[box_vertex_indices_to_remove] = False\n",
    "    remaining_verts = new_verts[keep_vertex_mask]\n",
    "\n",
    "    # Step 5: remap face indices\n",
    "    old_to_new = np.full(len(new_verts), -1, dtype=int)\n",
    "    old_to_new[np.where(keep_vertex_mask)[0]] = np.arange(len(remaining_verts))\n",
    "    for i, face in enumerate(remaining_faces_data):\n",
    "        remaining_faces_data[i]['vertex_indices'] = [old_to_new[v] for v in face['vertex_indices']]\n",
    "\n",
    "    remaining_faces = PlyElement.describe(remaining_faces_data, 'face')\n",
    "    return remaining_verts, remaining_faces\n",
    "\n",
    "def save_new_ply(mod_verts, mod_faces, boxes_removed, filename_prefix='TRsim_room_', mode='binary'):\n",
    "    num_removed = len(boxes_removed)\n",
    "    boxes_str = \"\".join(map(str, boxes_removed))\n",
    "    filename = f\"{filename_prefix}{num_removed}_{boxes_str}\"\n",
    "    \n",
    "    if mode == 'binary':\n",
    "        ply = PlyData([PlyElement.describe(mod_verts, 'vertex'), mod_faces], byte_order='<')\n",
    "        ply.write(os.path.join(STAGES_DIR, filename + \"_semantic.ply\"))\n",
    "    elif mode == 'ascii':\n",
    "        ply = PlyData([PlyElement.describe(mod_verts, 'vertex'), mod_faces], text=True)\n",
    "        ply.write(os.path.join(STAGES_DIR, filename + \"_ascii.ply\"))\n",
    "    else:\n",
    "        raise Exception(\"Mode must be 'binary' or 'ascii'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1f1a1430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "B = 10  # number of boxes\n",
    "R = [1]  # list of room indices\n",
    "\n",
    "labels = []\n",
    "\n",
    "for r in R:\n",
    "    base_ply = PlyData.read(os.path.join(STAGES_DIR, \"base\", f\"TRsim_room{r}.ply\"))\n",
    "    new_verts, faces = create_empty_ply(base_ply)\n",
    "\n",
    "    save_new_ply(new_verts, faces, [], filename_prefix=f'TRsim_room{r}_')\n",
    "    labels.append(0)\n",
    "\n",
    "    # Generate all combinations of boxes to remove (from 1 to B)\n",
    "    for num_to_remove in range(1, B + 1):\n",
    "        for boxes_to_remove in itertools.combinations(range(B), num_to_remove):\n",
    "            remaining_verts, remaining_faces = remove_boxes_from_ply(new_verts, faces, list(boxes_to_remove))\n",
    "            save_new_ply(remaining_verts, remaining_faces, boxes_to_remove, filename_prefix=f'TRsim_room{r}_')\n",
    "            labels.append(len(boxes_to_remove))\n",
    "\n",
    "np.save(os.path.join(BASE_DIR, \"data/output/TRsim_exp3/try1\", f\"labels_{len(R)}rooms_{str(B)}boxes.npy\"), np.array(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "100c216c",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(labels) == 2**B # amount of possible combinations, including the \"no_box_removed\" and \"all_boxes_removed\" situation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97908304",
   "metadata": {},
   "source": [
    "### Step 2: Create a ground truth label file\n",
    "\n",
    "This step is merged with the one before, as this is more efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5e9a1d",
   "metadata": {},
   "source": [
    "### Step 3: Run SoundSpaces 2.0\n",
    "\n",
    "Run Docker simsetup container with: \n",
    "\n",
    "(maybe: '''docker rm simsetup''')\n",
    "\n",
    "'''docker run -it --gpus all --name simsetup -v ~/ss/examples:/sound-spaces/examples -v ~/ss/data:/sound-spaces/data soundspaces:U20cudaglheadless /bin/bash'''\n",
    "\n",
    "'''cd sound-spaces'''\n",
    "\n",
    "'''python examples/TRsim.py'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae9b473",
   "metadata": {},
   "source": [
    "### Step 4: Concatenate mic channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "598f0d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "C = 1\n",
    "R = 50000\n",
    "N = 10\n",
    "S = 48000\n",
    "\n",
    "TRSIM = 'TRsim_exp3'\n",
    "FOLDER = 'try1'\n",
    "\n",
    "deconv = np.zeros((N, 10, S))\n",
    "\n",
    "if C == 1:\n",
    "    mics = [0]\n",
    "elif C == 2:\n",
    "    mics = [0, 6]\n",
    "elif C == 4:\n",
    "    mics = [0, 5, 6, 9]\n",
    "elif C == 10:\n",
    "    mics = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "\n",
    "for n in mics:\n",
    "    mic_rirs = np.load(BASE_DIR + f\"/data/output/{TRSIM}/{FOLDER}/deconvolved_{N}_{R}_mic{n}.npy\")\n",
    "    deconv[:, n, :] = mic_rirs.squeeze(1)\n",
    "\n",
    "output = BASE_DIR + f\"/data/output/{TRSIM}/{FOLDER}/deconvolved_{N}_{R}_{C}.npy\"\n",
    "np.save(output, deconv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1defba09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rsync -avz /home/student/ss/data/output/TRsim_exp3/try1/deconvolved_10_50000_1.npy menthe@10.201.224.12:/scsi_two/Menthe/TRsim_exp3/\n"
     ]
    }
   ],
   "source": [
    "data_folder_server = f\"menthe@10.201.224.12:/scsi_two/Menthe/{TRSIM}/\"\n",
    "print(f\"rsync -avz {output} {data_folder_server}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "82294a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scsi_two/Menthe/TRsim_human/deconvolved_10_50000_1.npy\n"
     ]
    }
   ],
   "source": [
    "print(\"/scsi_two/Menthe/TRsim_human/\"+f\"deconvolved_{N}_{R}_{C}.npy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
