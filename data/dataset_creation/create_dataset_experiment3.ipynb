{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "270c7e11",
   "metadata": {},
   "source": [
    "# Dataset Creation - TRsim Experiment 3\n",
    "\n",
    "R = amount of starting configurations with B boxes\n",
    "B = amount of boxes in the room at the start\n",
    "\n",
    "## Step 1: Create the foundation files\n",
    "\n",
    "Within the folder data/scene_datasets/TRsim_exp3/stages/:\n",
    "\n",
    "- (1x) TRsim_room.glb: floor + walls + ceiling mesh.\n",
    "\n",
    "- (Rx) TRsim.ply: export the room, as well as the boxes.\n",
    "\n",
    "- (1x) TRsim.house: .house file describing the room geometry, and the box locations.\n",
    "\n",
    "Within the folder data/scene_datasets/TRsim_exp3/objects/:\n",
    "\n",
    "- (1x) TRsim_box.glb: box mesh.\n",
    "\n",
    "And:\n",
    "\n",
    "- (1x) TRsim_material_config.json: Acoustic properties file\n",
    "\n",
    "## Step 1: Modify the _semantic.ply + .house\n",
    "\n",
    "Modify the .ply file to change the last x vertices (boxes) to different locations, as well as adding the right material \"object_id\". Save in the format \"N_semantic.ply\". \n",
    "\n",
    "Also, change the boxes' xyz locations in the .house file.\n",
    "\n",
    "## Step 2: Run SoundSpaces 2.0\n",
    "\n",
    "Load the file, rename to \"treated_room_object_semantic.ply\", run simulation, and save as \"N.wav\".\n",
    "\n",
    "## Step 3: Concatenate mic channels\n",
    "\n",
    "For now, the simulations are saved per mic. For the multi-channel cases, these files need to be concatenated into one \"deconvolved.npy\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34cc7c1",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2af1de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from plyfile import PlyData, PlyElement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbb38dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/student/ss/data/scene_datasets/TRsim_exp3/stages\n"
     ]
    }
   ],
   "source": [
    "BASE_DIR = \"/home/student/ss\"\n",
    "SIM_DIR = os.path.join(BASE_DIR, \"data/scene_datasets/TRsim_exp3\")\n",
    "STAGES_DIR = os.path.join(BASE_DIR, SIM_DIR, \"stages\")\n",
    "print(STAGES_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12617d74",
   "metadata": {},
   "source": [
    "### Step 1: Modify the _semantic.ply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3f2f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_empty_ply(base_ply):\n",
    "    base_verts = np.array(base_ply['vertex'].data) # (40,), where the first 33 correspond to the room, the last 8 to the box\n",
    "\n",
    "    verts_dtype = [\n",
    "        ('x', 'f4'), ('y', 'f4'), ('z', 'f4'),\n",
    "        ('red', 'u1'), ('green', 'u1'), ('blue', 'u1'),\n",
    "        ('object_id', 'i4')] # remove the alpha, add the object_id\n",
    "    \n",
    "    new_verts = np.empty(len(base_verts), dtype=verts_dtype)\n",
    "\n",
    "    new_verts['x'] = base_verts['x'] # last 8 will be overwritten\n",
    "    new_verts['y'] = base_verts['y'] # last 8 will be overwritten\n",
    "    new_verts['z'] = base_verts['z'] # does not change between measurement locations (vertex order does not change)\n",
    "    new_verts['red'] = base_verts['red'] # same\n",
    "    new_verts['green'] = base_verts['green'] # same\n",
    "    new_verts['blue'] = base_verts['blue'] # same\n",
    "\n",
    "    for v in range(len(new_verts)): # set all materials, does not change between measurement locations (vertex order does not change)\n",
    "        if new_verts['red'][v] == 254:\n",
    "            new_verts['object_id'][v] = 1 # wall material\n",
    "        elif new_verts['green'][v] == 254:\n",
    "            new_verts['object_id'][v] = 0 # floor material\n",
    "        elif new_verts['blue'][v] == 254:\n",
    "            new_verts['object_id'][v] = 2 # ceiling material\n",
    "        else:\n",
    "            new_verts['object_id'][v] = 3 # object material        \n",
    "        \n",
    "    faces = base_ply['face'] # unchanged, just sets which vertice ids correspond to which face (and vertex order does not change)\n",
    "    \n",
    "    return new_verts, faces\n",
    "\n",
    "def remove_box_from_ply(new_verts, faces, box):\n",
    "\n",
    "    is_box_vertex = new_verts['object_id'] == 3\n",
    "    box_vertex_indices = np.where(is_box_vertex)[0]\n",
    "\n",
    "    start = box * 8\n",
    "    end = start + 8\n",
    "    box_vertex_indices = box_vertex_indices[start:end]\n",
    "\n",
    "    faces_data = np.array(faces.data)  # structured array\n",
    "    keep_face_mask = []\n",
    "    for face in faces_data:\n",
    "        vertex_ids = face['vertex_indices']\n",
    "        if not any(v in box_vertex_indices for v in vertex_ids):\n",
    "            keep_face_mask.append(True)\n",
    "        else:\n",
    "            keep_face_mask.append(False)\n",
    "    keep_face_mask = np.array(keep_face_mask)\n",
    "    remaining_faces_data = faces_data[keep_face_mask]\n",
    "\n",
    "    keep_vertex_mask = np.ones(len(new_verts), dtype=bool)\n",
    "    keep_vertex_mask[box_vertex_indices] = False\n",
    "    remaining_verts = new_verts[keep_vertex_mask]\n",
    "\n",
    "    old_to_new = np.full(len(new_verts), -1, dtype=int)\n",
    "    old_to_new[np.where(keep_vertex_mask)[0]] = np.arange(len(remaining_verts))\n",
    "\n",
    "    for i, face in enumerate(remaining_faces_data):\n",
    "        remaining_faces_data[i]['vertex_indices'] = [old_to_new[v] for v in face['vertex_indices']]\n",
    "\n",
    "    remaining_faces = PlyElement.describe(remaining_faces_data, 'face')\n",
    "\n",
    "    return remaining_verts, remaining_faces\n",
    "\n",
    "def save_new_ply(mod_verts, mod_faces, box, filename='TRsim_room_', mode='binary'):\n",
    "    if mode == 'binary':\n",
    "        ply = PlyData([PlyElement.describe(mod_verts, 'vertex'), mod_faces], byte_order='<')\n",
    "        print(os.path.join(STAGES_DIR, filename + str(box) + \"_semantic.ply\"))\n",
    "        ply.write(os.path.join(STAGES_DIR, filename + str(box) + \"_semantic.ply\"))\n",
    "    elif mode == 'ascii': \n",
    "        ply = PlyData([PlyElement.describe(mod_verts, 'vertex'), mod_faces], text=True)\n",
    "        ply.write(os.path.join(STAGES_DIR, filename + str(box) + \"_ascii.ply\"))\n",
    "    else:\n",
    "        raise Exception(\"Please choose the mode to be either 'binary' or 'ascii'.\")\n",
    "    \n",
    "B = 10 # amount of boxes\n",
    "R = [1] # list of the starting configuration numbers, i.e. the rooms\n",
    "\n",
    "for r in R:\n",
    "    base_ply = PlyData.read(os.path.join(STAGES_DIR, \"base\", f\"TRsim_room{r}.ply\"))\n",
    "    new_verts, faces = create_empty_ply(base_ply)\n",
    "\n",
    "    for box in range(B):\n",
    "        remaining_verts, remaining_faces = remove_box_from_ply(new_verts, faces, box)\n",
    "        save_new_ply(remaining_verts, remaining_faces, box, filename=f'TRsim_room{str(r)}_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f1a1430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/student/ss/data/scene_datasets/TRsim_exp3/stages/TRsim_room1_0_semantic.ply\n",
      "/home/student/ss/data/scene_datasets/TRsim_exp3/stages/TRsim_room1_1_semantic.ply\n",
      "/home/student/ss/data/scene_datasets/TRsim_exp3/stages/TRsim_room1_2_semantic.ply\n",
      "/home/student/ss/data/scene_datasets/TRsim_exp3/stages/TRsim_room1_3_semantic.ply\n",
      "/home/student/ss/data/scene_datasets/TRsim_exp3/stages/TRsim_room1_4_semantic.ply\n",
      "/home/student/ss/data/scene_datasets/TRsim_exp3/stages/TRsim_room1_5_semantic.ply\n",
      "/home/student/ss/data/scene_datasets/TRsim_exp3/stages/TRsim_room1_6_semantic.ply\n",
      "/home/student/ss/data/scene_datasets/TRsim_exp3/stages/TRsim_room1_7_semantic.ply\n",
      "/home/student/ss/data/scene_datasets/TRsim_exp3/stages/TRsim_room1_8_semantic.ply\n",
      "/home/student/ss/data/scene_datasets/TRsim_exp3/stages/TRsim_room1_9_semantic.ply\n"
     ]
    }
   ],
   "source": [
    "B = 10 # amount of boxes\n",
    "R = [1] # list of the starting configuration numbers, i.e. the rooms\n",
    "\n",
    "for r in R:\n",
    "    base_ply = PlyData.read(os.path.join(STAGES_DIR, \"base\", f\"TRsim_room{r}.ply\"))\n",
    "    new_verts, faces = create_empty_ply(base_ply)\n",
    "\n",
    "    for box in range(B):\n",
    "        remaining_verts, remaining_faces = remove_box_from_ply(new_verts, faces, box)\n",
    "        save_new_ply(remaining_verts, remaining_faces, box, filename=f'TRsim_room{str(r)}_')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5e9a1d",
   "metadata": {},
   "source": [
    "### Step 3: Run SoundSpaces 2.0\n",
    "\n",
    "Run Docker simsetup container with: \n",
    "\n",
    "(maybe: '''docker rm simsetup''')\n",
    "\n",
    "'''docker run -it --gpus all --name simsetup -v ~/ss/examples:/sound-spaces/examples -v ~/ss/data:/sound-spaces/data soundspaces:U20cudaglheadless /bin/bash'''\n",
    "\n",
    "'''cd sound-spaces'''\n",
    "\n",
    "'''python examples/TRsim.py'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae9b473",
   "metadata": {},
   "source": [
    "### Step 4: Concatenate mic channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598f0d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "C = 1\n",
    "R = 50000\n",
    "N = 1000\n",
    "S = 48000\n",
    "\n",
    "TRSIM = 'TRsim_exp3'\n",
    "FOLDER = 'try1'\n",
    "\n",
    "deconv = np.zeros((N, 10, S))\n",
    "\n",
    "if C == 1:\n",
    "    mics = [0]\n",
    "elif C == 2:\n",
    "    mics = [0, 6]\n",
    "elif C == 4:\n",
    "    mics = [0, 5, 6, 9]\n",
    "elif C == 10:\n",
    "    mics = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "\n",
    "for n in mics:\n",
    "    mic_rirs = np.load(BASE_DIR + f\"/data/output/{TRSIM}/{FOLDER}/deconvolved_{N}_{R}_mic{n}.npy\")\n",
    "    deconv[:, n, :] = mic_rirs.squeeze(1)\n",
    "\n",
    "output = BASE_DIR + f\"/data/output/{TRSIM}/{FOLDER}/deconvolved_{N}_{R}_{C}.npy\"\n",
    "np.save(output, deconv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1defba09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rsync -avz /home/student/ss/data/output/TRsim_human_pose/human_pose/deconvolved_1000_50000_1.npy menthe@10.201.224.12:/scsi_two/Menthe/TRsim_human_pose/\n"
     ]
    }
   ],
   "source": [
    "data_folder_server = f\"menthe@10.201.224.12:/scsi_two/Menthe/{TRSIM}/\"\n",
    "print(f\"rsync -avz {output} {data_folder_server}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "82294a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scsi_two/Menthe/TRsim_human/deconvolved_1000_50000_1.npy\n"
     ]
    }
   ],
   "source": [
    "print(\"/scsi_two/Menthe/TRsim_human/\"+f\"deconvolved_{N}_{R}_{C}.npy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
